from torchvision.models import Inception3
import torch.utils.model_zoo as model_zoo
import torch.nn as nn

model_urls = {
    # Inception v3 ported from TensorFlow
    'inception_v3_google': 'https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth',
}

def inception_v3(pretrained=False, **kwargs):
    r"""Inception v3 model architecture from
    `"Rethinking the Inception Architecture for Computer Vision" <http://arxiv.org/abs/1512.00567>`_.
    .. note::
        **Important**: In contrast to the other models the inception_v3 expects tensors with a size of
        N x 3 x 299 x 299, so ensure your images are sized accordingly.
    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet
        progress (bool): If True, displays a progress bar of the download to stderr
        aux_logits (bool): If True, add an auxiliary branch that can improve training.
            Default: *True*
        transform_input (bool): If True, preprocesses the input according to the method with which it
            was trained on ImageNet. Default: *False*
    """
    # if pretrained:
    #     if 'transform_input' not in kwargs:
    #         kwargs['transform_input'] = True
    #     if 'aux_logits' in kwargs:
    #         original_aux_logits = kwargs['aux_logits']
    #         kwargs['aux_logits'] = True
    #     else:
    #         original_aux_logits = True
    #     model = Inception3(**kwargs)
    #     state_dict = model_zoo.load_url(model_urls['inception_v3_google'],model_dir='/userhome/renqian/download_models')
    #     model.load_state_dict(state_dict)
    #     model.aux_logits = False
    #     del model.AuxLogits
    #     inception_v3.fc = nn.Linear(2048, 2)
    #     return model
    return Inception3(**kwargs)
if __name__=='__main__':
    inceptionv3=inception_v3(num_classes=2,aux_logits=True)
